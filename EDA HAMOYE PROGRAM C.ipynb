{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET DESCRIPTION\n",
    "\n",
    "Stability of the Grid System\n",
    "\n",
    "Electrical grids require a balance between electricity supply and demand in order to be stable. \n",
    "Conventional systems achieve this balance through demand-driven electricity production. \n",
    "For future grids with a high share of inflexible (i.e., renewable) energy source, the concept of demand response is \n",
    "a promising solution. This implies changes in electricity consumption in relation to electricity price changes. \n",
    "In this work, we’ll build a binary classification model to predict if a grid is stable or unstable using the UCI Electrical \n",
    "Grid Stability Simulated dataset.\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
    "\n",
    "It has 12 primary predictive features and two dependent variables.\n",
    "\n",
    "Predictive features:\n",
    "\n",
    "    'tau1' to 'tau4': the reaction time of each network participant, a real value within the range 0.5 to 10\n",
    "        ('tau1' corresponds to the supplier node, 'tau2' to 'tau4' to the consumer nodes);\n",
    "    'p1' to 'p4': nominal power produced (positive) or consumed (negative) by each network participant, \n",
    "        a real value within the range -2.0 to -0.5 for consumers ('p2' to 'p4'). As the total power consumed equals \n",
    "        the total power generated, p1 (supplier node) = - (p2 + p3 + p4);\n",
    "    'g1' to 'g4': price elasticity coefficient for each network participant, a real value within the range 0.05 to 1.00 \n",
    "        ('g1' corresponds to the supplier node, 'g2' to 'g4' to the consumer nodes; 'g' stands for 'gamma');\n",
    "\n",
    "Dependent variables:\n",
    "\n",
    "    'stab': the maximum real part of the characteristic differential equation root \n",
    "        (if positive, the system is linearly unstable; if negative, linearly stable);\n",
    "    'stabf': a categorical (binary) label ('stable' or 'unstable').\n",
    "\n",
    "Because of the direct relationship between 'stab' and 'stabf' ('stabf' = 'stable' if 'stab' <= 0, 'unstable' otherwise), \n",
    "'stab' should be dropped and 'stabf' will remain as the sole dependent variable (binary classification).\n",
    "\n",
    "Split the data into an 80-20 train-test split with a random state of “1”. Use the standard scaler to transform the \n",
    "train set (x_train, y_train) and the test set (x_test). Use scikit learn to train a random forest and extra trees classifier. \n",
    "And use xgboost and lightgbm to train an extreme boosting model and a light gradient boosting model. \n",
    "Use random_state = 1 for training all models and evaluate on the test set. \n",
    "\n",
    "Also, to improve the Extra Trees Classifier, you will use the following parameters \n",
    "(number of estimators, minimum number of samples, minimum number of samples for leaf node and the number of features to \n",
    " consider when looking for the best split) for the hyperparameter grid needed to run a Randomized Cross Validation Search \n",
    "(RandomizedSearchCV). \n",
    "\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "                       'min_samples_split': min_samples_split,\n",
    "\n",
    "                       'max_features': max_features}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DIANNE ATTAH'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\DIANNE ATTAH\\Desktop\\datascience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect data\n",
    "   Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "data = pd.read_csv('Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.999209</td>\n",
       "      <td>9.109247</td>\n",
       "      <td>3.784066</td>\n",
       "      <td>4.267788</td>\n",
       "      <td>4.429669</td>\n",
       "      <td>-1.857139</td>\n",
       "      <td>-0.670397</td>\n",
       "      <td>-1.902133</td>\n",
       "      <td>0.261793</td>\n",
       "      <td>0.077930</td>\n",
       "      <td>0.542884</td>\n",
       "      <td>0.469931</td>\n",
       "      <td>-0.017385</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.710166</td>\n",
       "      <td>3.765204</td>\n",
       "      <td>6.929314</td>\n",
       "      <td>8.818562</td>\n",
       "      <td>2.397419</td>\n",
       "      <td>-0.614590</td>\n",
       "      <td>-1.208826</td>\n",
       "      <td>-0.574004</td>\n",
       "      <td>0.177890</td>\n",
       "      <td>0.397977</td>\n",
       "      <td>0.402046</td>\n",
       "      <td>0.376630</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.953512</td>\n",
       "      <td>1.379125</td>\n",
       "      <td>5.719400</td>\n",
       "      <td>7.870307</td>\n",
       "      <td>3.224495</td>\n",
       "      <td>-0.748998</td>\n",
       "      <td>-1.186517</td>\n",
       "      <td>-1.288980</td>\n",
       "      <td>0.371385</td>\n",
       "      <td>0.633204</td>\n",
       "      <td>0.732741</td>\n",
       "      <td>0.380544</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.689852</td>\n",
       "      <td>4.007747</td>\n",
       "      <td>1.478573</td>\n",
       "      <td>3.733787</td>\n",
       "      <td>4.041300</td>\n",
       "      <td>-1.410344</td>\n",
       "      <td>-1.238204</td>\n",
       "      <td>-1.392751</td>\n",
       "      <td>0.269708</td>\n",
       "      <td>0.250364</td>\n",
       "      <td>0.164941</td>\n",
       "      <td>0.482439</td>\n",
       "      <td>-0.038677</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.841496</td>\n",
       "      <td>1.413822</td>\n",
       "      <td>9.769856</td>\n",
       "      <td>7.641616</td>\n",
       "      <td>4.727595</td>\n",
       "      <td>-1.991363</td>\n",
       "      <td>-0.857637</td>\n",
       "      <td>-1.878594</td>\n",
       "      <td>0.376356</td>\n",
       "      <td>0.544415</td>\n",
       "      <td>0.792039</td>\n",
       "      <td>0.116263</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "5  6.999209  9.109247  3.784066  4.267788  4.429669 -1.857139 -0.670397   \n",
       "6  6.710166  3.765204  6.929314  8.818562  2.397419 -0.614590 -1.208826   \n",
       "7  6.953512  1.379125  5.719400  7.870307  3.224495 -0.748998 -1.186517   \n",
       "8  4.689852  4.007747  1.478573  3.733787  4.041300 -1.410344 -1.238204   \n",
       "9  9.841496  1.413822  9.769856  7.641616  4.727595 -1.991363 -0.857637   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  \n",
       "5 -1.902133  0.261793  0.077930  0.542884  0.469931 -0.017385    stable  \n",
       "6 -0.574004  0.177890  0.397977  0.402046  0.376630  0.005954  unstable  \n",
       "7 -1.288980  0.371385  0.633204  0.732741  0.380544  0.016634  unstable  \n",
       "8 -1.392751  0.269708  0.250364  0.164941  0.482439 -0.038677    stable  \n",
       "9 -1.878594  0.376356  0.544415  0.792039  0.116263  0.012383  unstable  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top five in file(to preview the dataset)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last five in file(to preview the dataset)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check the number of rows and column\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the dataset\n",
    "   creating different plots to check relationship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x225022ceb08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"stabf\", data=data)\n",
    "# There are many unstable electrical grids so there is little balance in electricity supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_categories = data.Category.unique().size\n",
    "#sns.countplot(data=data ,x = 'stabf', hue = 'islong, saturation=1,xerr=7*np.arange(num_categories),edgecolor=(0,0,0),linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x=\"stabf\",hue = \"p1\", data=data,bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2',\n",
       "       'g3', 'g4', 'stab', 'stabf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check target variable therefore showing the difference between classes\n",
    "data[ 'stabf' ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# dataset information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling\n",
    "   To clean the data by removing NaN and columns that are unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "data.isnull().sum()# there is no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tau1  tau2  tau3  tau4    p1    p2    p3    p4    g1    g2    g3    g4  \\\n",
       "0     True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "1     True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "2     True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "3     True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "4     True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "9995  True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "9996  True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "9997  True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "9998  True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "9999  True  True  True  True  True  True  True  True  True  True  True  True   \n",
       "\n",
       "      stab  stabf  \n",
       "0     True   True  \n",
       "1     True   True  \n",
       "2     True   True  \n",
       "3     True   True  \n",
       "4     True   True  \n",
       "...    ...    ...  \n",
       "9995  True   True  \n",
       "9996  True   True  \n",
       "9997  True   True  \n",
       "9998  True   True  \n",
       "9999  True   True  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the column that is not needed(unimportant variables)\n",
    "Drop_cols = ['stab']\n",
    "data = data.drop(Drop_cols, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "\n",
       "         p4        g1        g2        g3        g4     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  unstable  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)# new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unstable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unstable\n",
       "0            1\n",
       "1            0\n",
       "2            1\n",
       "3            1\n",
       "4            1\n",
       "...        ...\n",
       "9995         1\n",
       "9996         0\n",
       "9997         0\n",
       "9998         1\n",
       "9999         1\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get dummy variable for category\n",
    "pd.get_dummies(data['stabf'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies(data['tau4'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4  \n",
       "count  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000  \n",
       "std        0.274255      0.274255  \n",
       "min        0.050054      0.050028  \n",
       "25%        0.287514      0.287494  \n",
       "50%        0.525015      0.525002  \n",
       "75%        0.762440      0.762433  \n",
       "max        0.999982      0.999930  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     10000\n",
       "tau2     10000\n",
       "tau3     10000\n",
       "tau4     10000\n",
       "p1       10000\n",
       "p2       10000\n",
       "p3       10000\n",
       "p4       10000\n",
       "g1       10000\n",
       "g2       10000\n",
       "g3       10000\n",
       "g4       10000\n",
       "stabf        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('stabf',axis=1)\n",
    "y=data['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    5092\n",
       "stable      2908\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9995    1\n",
       "9996    0\n",
       "9997    0\n",
       "9998    1\n",
       "9999    1\n",
       "Name: stabf, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding the categorical feature. \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data.stabf = encoder.fit_transform(data.stabf)\n",
    "#let's preview the encoded feature\n",
    "data.stabf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train_balanced, y_balanced = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n      stable       0.85      0.80      0.83       712\\n    unstable       0.89      0.92      0.91      1288\\n\\n    accuracy                           0.88      2000\\n   macro avg       0.87      0.86      0.87      2000\\nweighted avg       0.88      0.88      0.88      2000\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 572,  140],\n",
       "       [ 100, 1188]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "predictions = logreg.predict(x_test)\n",
    "confusion_matrix(y_test,predictions)#(y_true=y_test, y_pred=new_predictions) #labels=['2A', '3A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1344, in fit\n",
      "    accept_large_sparse=solver != 'liblinear')\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 598, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 754, in __array__\n",
      "    return np.asarray(self.array, dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\", line 184, in __array__\n",
      "    return np.asarray(self._ndarray, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'unstable'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1344, in fit\n",
      "    accept_large_sparse=solver != 'liblinear')\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 598, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 754, in __array__\n",
      "    return np.asarray(self.array, dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\", line 184, in __array__\n",
      "    return np.asarray(self._ndarray, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'unstable'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1344, in fit\n",
      "    accept_large_sparse=solver != 'liblinear')\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 598, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 754, in __array__\n",
      "    return np.asarray(self.array, dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\", line 184, in __array__\n",
      "    return np.asarray(self._ndarray, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'unstable'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1344, in fit\n",
      "    accept_large_sparse=solver != 'liblinear')\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 598, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 754, in __array__\n",
      "    return np.asarray(self.array, dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\", line 184, in __array__\n",
      "    return np.asarray(self._ndarray, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'unstable'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1344, in fit\n",
      "    accept_large_sparse=solver != 'liblinear')\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 598, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 754, in __array__\n",
      "    return np.asarray(self.array, dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\", line 184, in __array__\n",
      "    return np.asarray(self._ndarray, dtype=dtype)\n",
      "  File \"C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: 'unstable'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validation and accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logreg, y_test,predictions, cv=5, scoring='f1_macro')\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.0\n"
     ]
    }
   ],
   "source": [
    "#Accuracy.py\n",
    "accuracy = accuracy_score(y_test,predictions)#(y_true=y_test, y_pred=new_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIANNE ATTAH\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1305: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if pos_label not in present_labels:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['stable', 'unstable'], dtype='<U8')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-10d24932abb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Precision.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#(y_true=y_test, y_pred=new_predictions, pos_label='2A')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1673\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1484\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1306\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: \"\n\u001b[1;32m-> 1308\u001b[1;33m                                      \"%r\" % (pos_label, present_labels))\n\u001b[0m\u001b[0;32m   1309\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['stable', 'unstable'], dtype='<U8')"
     ]
    }
   ],
   "source": [
    "#Precision.py\n",
    "precision = precision_score(y_test,predictions)#(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('Precision: {}'.format(round(precision*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['stable', 'unstable'], dtype='<U8')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-8c82f635cb72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Recall.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#(y_true=y_test, y_pred=new_predictions, pos_label='2A')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Recall: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1787\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1789\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1790\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1484\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1306\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: \"\n\u001b[1;32m-> 1308\u001b[1;33m                                      \"%r\" % (pos_label, present_labels))\n\u001b[0m\u001b[0;32m   1309\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['stable', 'unstable'], dtype='<U8')"
     ]
    }
   ],
   "source": [
    "#Recall.py\n",
    "recall = recall_score(y_test,predictions)#(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('Recall: {}'.format(round(recall*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "#run for every split\n",
    "for train_index, test_index in skf.split(normalised_train_df, y_balanced):\n",
    "  x_train, x_test = np.array(normalised_train_df)[train_index],  \n",
    "                    np.array(normalised_train_df)[test_index]\n",
    "  y_train, y_test  = y_balanced[train_index], y_balanced[test_index]\n",
    "  model = LogisticRegression().fit(x_train, y_train)\n",
    "  #save result to list\n",
    "  f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.split(normalised_train_df) \n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for every split\n",
    "for train_index, test_index in kf.split(normalised_train_df):\n",
    "  x_train, x_test = normalised_train_df.iloc[train_index],\n",
    "                    normalised_train_df.iloc[test_index]\n",
    "  y_train, y_test = y_balanced[train_index],\n",
    "                    y_balanced[test_index]\n",
    "  model = LogisticRegression().fit(x_train, y_train)\n",
    "  #save result to list\n",
    "  f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), \n",
    "                   pos_label='2A')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stratified K-Fold Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Leave One Out Cross Validation (LOOCV)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(LogisticRegression(), normalised_train_df, y_balanced, cv=loo, \n",
    "                         scoring='f1_macro')\n",
    "average_score = scores.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Tree-Based Methods and The Support Vector Machine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(normalised_train_df, y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score {}\".format(round(accuracy_score(y_test, dec_pred), 3)))\n",
    "print(\"Precision score for label 2A %.3f\" % (precision_score(y_test, dec_pred, pos_label='2A')))\n",
    "print(\"Recall score for label 2A {}\".format(round(recall_score(y_test, dec_pred, pos_label='2A'), 3)))\n",
    "print(\"F1 score %.3f\" % (f1_score(y_test, dec_pred, pos_label='2A')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dec_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost with random forest\n",
    "from xgboost import XGBRFClassifier\n",
    "extreme = XGBRFClassifier(random_state=1)\n",
    "extreme.fit(normalised_train_df, y_balanced)\n",
    "extreme_pred = extreme.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, extreme_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra tree classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree = ExtraTreesClassifier(random_state=1)\n",
    "tree.fit(normalised_train_df, y_balanced)\n",
    "tree_pred = tree.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_estimators = [10, 50, 100, 250, 400]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = RandomizedSearchCV(tree, hyperparameter_grid, random_state=1)\n",
    "search = clf.fit(normalised_train_df, y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for the best parameter for the model\n",
    "search.best_params_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with this parameter to test the model's performance\n",
    "tree_param = ExtraTreesClassifier(n_estimators=100, min_samples_split=9, \n",
    "                                 min_samples_leaf=2, max_features='auto', random_state=1)\n",
    "tree_param.fit(normalised_train_df, y_balanced)\n",
    "tree_param_pred = tree_param.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report for this hyperparameter tuning\n",
    "print(classification_report(y_test, tree_param_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-30-e346cc12dd05>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-e346cc12dd05>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    X_scaled, y, stratify=y, test_size=0.2, random_state=1\u001b[0m\n\u001b[1;37m                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, stratify=y, test_size=0.2, random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'top 20 tau1 count')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the most used supplier node\n",
    "plt.figsize=(20,10)\n",
    "data[ 'tau1' ].value_counts().nlargest(20).plot(kind='bar')\n",
    "plt.title('top 20 tau1 count')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
